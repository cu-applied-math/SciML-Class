{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu-applied-math/SciML-Class/blob/main/Labs/lab06a_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7WF9h7rlHHH"
      },
      "source": [
        "# Part 1 Computational Costs\n",
        "In this part of the lab you will be aiming to estimate the computational cost of stepping functions\n",
        "for:\n",
        "- Gradient Descent: $$x_{i+1} = x_i - \\alpha \\nabla f(x_i)$$\n",
        "- Newtons Method: $$x_{i+1} = x_i - H_f^{-1} \\nabla f(x_i)$$  \n",
        "In applications, we want to know how our algorithms scale,\n",
        "but may not be able to analytically know how expensive each step is,\n",
        "or we want to check that our analysis\n",
        "matches with experimental results.\n",
        "\n",
        "For this problem we will be effectively generating least squares problem (code provided), then taking one optimization step with each method.\n",
        "$$f(x) = \\tfrac{1}{2}\\|Ax-b\\|_2^2, \\nabla f = A^T(Ax-b), H_f = (A^TA)^{-1}A^T(Ax-b)$$\n",
        "This has a closed form solution, and in fact the newton step is equivalent to applying the closed form solution. In general, we do care about **Nonlinear** least squares problem.\n",
        "$$f(x) = \\tfrac{1}{2}\\|G(x)-b\\|_2^2, \\nabla f = J_G^T(G(x)-b), H_f = H_G[(Ax-b]] + J_G^TJ_G$$\n",
        "We are just generating linear least squares problems for computational ease.\n",
        "\n",
        "## A. Compute the Cost Analytically\n",
        "Similar to the homework compute the computational cost on paper, then we will compare this to our numerical results.\n",
        "\n",
        "## B. Run an experiment to see if our analysis matches the data\n",
        "For this problem, we give to inputs $N,M$ which are integers to two functions `foo1, foo2`. We want to estimate\n",
        "how each function's cost scales as a function of those inputs (think $O(N^kM^l)$). Good functions to use would be\n",
        "`time` to get wall times around function calls while calling the functions at various inputs. Then you can plot the results and possible pose least square problems to estimate the rates\n",
        "\n",
        "- **hint**: log-scale may be important\n",
        "- **hint**: perhaps fix one input to estimate the rate with the other\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dH8sHEpklHHI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "from numpy.random import random, randn, rand\n",
        "from numpy import sqrt\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CD-5iZ7XlHHI"
      },
      "outputs": [],
      "source": [
        "## Dont mess with thes\n",
        "def buildLeastSquares(N, M, noise_level=1, debug=False):\n",
        "  start = time()\n",
        "  A = random((M,N))\n",
        "  if debug: print(f'rand {time() - start}')\n",
        "  start = time()\n",
        "  np.fill_diagonal(A,10)\n",
        "  if debug: print(f'diag reg {time() - start}')\n",
        "  start = time()\n",
        "  x = rand(N)\n",
        "  b = A@x + noise_level*randn(M)\n",
        "  if debug: print(f'b {time() - start}')\n",
        "  return A, b\n",
        "def gradDescentStep(x, A, b, step_sz=1):\n",
        "  return x - step_sz * A.T@(A@x -b)\n",
        "def newtonStep(x, A, b):\n",
        "  return x - np.linalg.solve(A.T@A, A.T@(A@x - b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "If0TDMnqlHHJ",
        "outputId": "ec0ad484-be6f-4947-c583-073b7af04854"
      },
      "outputs": [],
      "source": [
        "debug = False\n",
        "base = 10\n",
        "stop = 6\n",
        "Ns = (10**np.arange(start=2.0,stop=4,step=0.25)).astype(int)\n",
        "Ms = (10**np.arange(start=2.0,stop=5,step=0.25)).astype(int)\n",
        "numN, numM = len(Ns), len(Ms)\n",
        "gradTimes = np.zeros((numN,numM))\n",
        "newtonTimes = np.zeros((numN,numM))\n",
        "for n, N in enumerate(Ns):\n",
        "    for m, M in enumerate(Ms):\n",
        "        if M < N:\n",
        "            # only want over determined (or determined systems)\n",
        "            continue\n",
        "        if debug: print(f'{N=}, {M=}\\n')\n",
        "        pass\n",
        "        ## You should be running algos and timing things here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5VA82PZMlHHJ"
      },
      "outputs": [],
      "source": [
        "## Plot the results in a way where you can see how the methods scale in N\n",
        "## Estimate the exponential rates somehow...\n",
        "# print(f'GradDesc is O(N^{...})')\n",
        "# print(f'Newton is O(N^{...})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "13PAoIM1lHHJ",
        "outputId": "fa902275-1d11-46fe-d137-dd36e4f42463"
      },
      "outputs": [],
      "source": [
        "## Plot the results in a way where you can see how the methods scale in M\n",
        "## Estimate the exponential rates somehow...\n",
        "# print(f'GradDesc is O(M^{...})')\n",
        "# print(f'Newton is O(M^{...})')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
