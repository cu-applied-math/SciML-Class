{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/Ei4Hv4wey1ZUekyiompQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu-applied-math/SciML-Class/blob/main/Labs/lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5 for SciML\n",
        "Why do we hvae validation and testing sets?"
      ],
      "metadata": {
        "id": "HVxFoz_1eIll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XJVt6Lu1L8E"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-sided [Hoeffding inequality](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality#Special_Case:_Bernoulli_RVs) for Bernoulli r.v.\n",
        "$$\n",
        "\\mathbb{P}\\left[ \\left| \\frac{1}{n}S_n - \\mu  \\right| \\ge t\\right] \\le 2 \\exp\\left( -2nt^2\\right)\n",
        "$$\n",
        "where $S_n=X_1+X_2+\\ldots+X_n$ is the sum of $n$ **independent** Bernoulli random variables.  Recall $X$ is a Bernoulli random variable (with some parameter $p$) if it takes on two possible values, $\\{0,1\\}$, and is equal to $1$ with probability $p$ and equal to $0$ with probability $1-p$.\n",
        "\n",
        "## Part 1\n",
        "Let $\\mu$ be the true risk of a binary classifier $f$ (using the 0-1 loss $\\ell$), and suppose we have $n$ independent samples (that are also independent of $f$), and let $\\frac{1}{n}S_n$ be the empirical risk (still using the 0-1 loss) on these samples.  (Think of these as validation or testing samples)\n",
        "\n",
        "**Q**: If we want to estimate $\\mu$ to an accuracy of $\\pm t$, with a confidence of $p=1-\\alpha$, how many samples $n$ do we need? Do this for $t=0.001, 0.01, 0.02$ and $0.05$, and for $\\alpha$ being $10^{-1},10^{-2},10^{-3},10^{-4},10^{-5}$. Make a table of the resulting $n$ values.\n",
        "\n",
        "Comment on whether $p$ or $t$ has a \"bigger effect\".\n",
        "\n",
        "**A**:"
      ],
      "metadata": {
        "id": "vaAhwx6u11ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep=\"\"  # for printing to screen\n",
        "# sep=\"|\" # for copying to markdown\n",
        "\n",
        "\n",
        "pList = np.logspace(-5,-1,5)\n",
        "print(end=sep)\n",
        "print(\"        \",end=sep)\n",
        "for p in pList:\n",
        "    print(f\"{p:10.0e}\",end=sep)\n",
        "    n = np.log(2/p)/(2*0.001**2)\n",
        "print(flush=True)\n",
        "for t in [0.001, 0.01, 0.02, 0.05]:\n",
        "    nValues = []\n",
        "    print(end=sep)\n",
        "    print(f\"{t:.3f}\",end=\"\\t\")\n",
        "    print(end=sep)\n",
        "    for p in pList:\n",
        "\n",
        "        n = ???????\n",
        "\n",
        "        print(f\"{int(n):-10d}\",end=sep)\n",
        "    print(flush=True)\n",
        "\n",
        "# t = 0.025\n",
        "# p = 1-.999\n",
        "# n = np.log(2/p)/(2*t**2)\n",
        "# print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_nLztxz10ne",
        "outputId": "08881ac1-c398-4db5-c173-2749eb66f274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             1e-05     1e-04     1e-03     1e-02     1e-01\n",
            "0.001\t   6103036   4951743   3800451   2649158   1497866\n",
            "0.010\t     61030     49517     38004     26491     14978\n",
            "0.020\t     15257     12379      9501      6622      3744\n",
            "0.050\t      2441      1980      1520      1059       599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2"
      ],
      "metadata": {
        "id": "y6DVCjMCHJq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "9UxIKfMY4uKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(101)\n",
        "d = 1  # dimension\n",
        "\n",
        "def get_feature_samples(n):\n",
        "    return torch.rand( (n,d) )-0.5 # uniform in [-.5,5]^d\n",
        "\n",
        "def f(x):\n",
        "    \"\"\" the *true* function that we're trying to learn\n",
        "    Should be 0 and 1 outputs\n",
        "    \"\"\"\n",
        "    y = (torch.sign( torch.sin( 15*x + 50*x**2 ) ) + 1 )/2\n",
        "    return y.long() # the datatype torch expects for classification\n",
        "\n",
        "# if d == 1:\n",
        "#     # Easy to plot\n",
        "#     X_plot = torch.linspace(-.5,.5,300)\n",
        "#     y_plot = f(X_plot)\n",
        "#     plt.plot( X_plot, y_plot )\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "n_test      = int(1e5) # Pick enough to make this the \"truth\"\n",
        "X_test      = get_feature_samples(n_test)\n",
        "y_test      = f(X_test) # can use torch.vmap if needed\n",
        "testset     = torch.utils.data.TensorDataset(X_test,  y_test)\n",
        "testloader  = torch.utils.data.DataLoader(testset,batch_size=1000)\n",
        "\n",
        "vals,bins   = torch.histogram(y_test.float(),bins=2)\n",
        "print(vals/n_test) # check if the data is approximately well-balanced\n",
        "# print(bins)\n",
        "\n",
        "\n",
        "class Net( nn.Module ):\n",
        "    \"\"\" A simple fully-connected neural net, all hidden layers the same size\n",
        "    This does binary classification by default (outputDim=2), setup for cross-entropy loss\n",
        "    \"\"\"\n",
        "    def __init__(self, nHiddenLayers=5, width=100, activation = nn.ReLU(), outputDim=2, inputDim = 1):\n",
        "        super().__init__()\n",
        "        # Construct a net as instructed (all hidden layers of the same size)\n",
        "        self.net = []\n",
        "        self.net.append(nn.Linear(inputDim, width))\n",
        "        self.net.append( activation )\n",
        "        for i in range(nHiddenLayers):\n",
        "            self.net.append(nn.Linear(width, width))\n",
        "            self.net.append( activation )\n",
        "        self.net.append(nn.Linear(width, outputDim))\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def empiricalRisk( model, dataloader ):\n",
        "    \"\"\" We need a dataloader, not a dataset\n",
        "    (otherwise the size of the tensor isn't correct)\n",
        "    Assumes the true labels are [0,1,...,outputdim-1]\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total   = 0\n",
        "        correct = 0\n",
        "        for data in dataloader:\n",
        "            inputs, trueLabels = data\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs.data, 1)\n",
        "            total   += trueLabels.size(0)\n",
        "            # Careful: if predicted is of size (batchSize,1)\n",
        "            #   and trueLabels are of size (batchSize,) then using \"==\"\n",
        "            #   will implicitly broadcast them to the wrong size!\n",
        "            correct += (predicted.ravel() == trueLabels.ravel() ).sum().item()\n",
        "            # We did .sum() in case batch size > 1\n",
        "    return correct/total\n",
        "\n",
        "def train_model( trainloader, optimizer, epochs = 30, criterion = nn.CrossEntropyLoss()  ):\n",
        "    \"\"\"\n",
        "    You don't explicitly pass in the model, but that's implicit in the optimizer\n",
        "    \"\"\"\n",
        "    for t in range(epochs):\n",
        "        runningLoss = 0.\n",
        "        for data in trainloader:\n",
        "            inputs, trueLabels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss    = criterion(outputs,trueLabels.flatten() )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            runningLoss += loss.item()"
      ],
      "metadata": {
        "id": "OM-93qkpHc1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(nHiddenLayers=3, width=20 )\n",
        "trueRisk    = empiricalRisk(model, testloader)\n",
        "print(f\"True risk: {trueRisk}\")"
      ],
      "metadata": {
        "id": "BEUk1-rZKgpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: choose the best from among many models\n"
      ],
      "metadata": {
        "id": "nJ54ZcBpVrZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a single validation set...\n",
        "X_valid     = get_feature_samples(n_valid)\n",
        "y_valid     = f(X_valid)\n",
        "validset    = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "validloader = torch.utils.data.DataLoader(validset,batch_size=1000)\n",
        "\n",
        "...."
      ],
      "metadata": {
        "id": "l032hDLCJUca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: training and choosing best hyperparameters"
      ],
      "metadata": {
        "id": "OkExQPoFTZX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train     = int(1e3) # not too large, in order to keep this fast\n",
        "X_train     = get_feature_samples(n_train)\n",
        "y_train     = f(X_train)\n",
        "trainset    = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
        "criterion   = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use a single validation set...\n",
        "X_valid     = get_feature_samples(n_valid)\n",
        "y_valid     = f(X_valid)\n",
        "validset    = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
        "validloader = torch.utils.data.DataLoader(validset,batch_size=1000)\n",
        "\n",
        "# Hyperparameters:\n",
        "nHiddenLayers = 3\n",
        "width         = 20\n",
        "learning_rate = 0.01\n",
        "epochs        = 1  # let's make it fast!\n",
        "\n",
        "\n",
        "...\n",
        "\n",
        "    model = Net(nHiddenLayers=nHiddenLayers, width=width )\n",
        "    model.train()\n",
        "    optimizer     = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "    # Train it\n",
        "    train_model( trainloader, optimizer, epochs=epochs )\n",
        "\n",
        "\n",
        "...\n"
      ],
      "metadata": {
        "id": "ok1LqF5_MYpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}